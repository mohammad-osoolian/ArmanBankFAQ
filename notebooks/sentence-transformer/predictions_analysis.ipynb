{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data"
      ],
      "metadata": {
        "id": "0ZSvJlNoqm1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "Bwj4v89uzpcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "vkqkPzdWvUST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def topk_accuracy(similarities, labels, k = 1) -> float:\n",
        "    topk_values, topk_indices = torch.topk(similarities, k=k, dim=1)\n",
        "    top_predicts = topk_indices + 1\n",
        "    matches = torch.any(top_predicts == labels.unsqueeze(1), dim=1)\n",
        "    topk_acc = matches.float().mean().item()\n",
        "    return topk_acc\n"
      ],
      "metadata": {
        "id": "GYl9mNccj1zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# key variables"
      ],
      "metadata": {
        "id": "zmVJdGIfz2kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! hf auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ULfvDiP6QVcb",
        "outputId": "4d33483f-ecd4-42b0-f571-806695a49369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "The token `colab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `colab`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_path = '/content/Ka-ChatBot_BenchMark.xlsx'\n",
        "# models = ['PartAI/Tooka-SBERT-V2-Large', 'xmanii/maux-gte-persian', 'BAAI/bge-m3']\n",
        "model_id = 'PartAI/Tooka-SBERT-V2-Large'\n"
      ],
      "metadata": {
        "id": "tq4hLEViz6W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load and prepare data"
      ],
      "metadata": {
        "id": "TchRf4tgztt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "faq_df = pd.read_excel(sheet_path, sheet_name=\"faq\", index_col='idx')\n",
        "samples_df = pd.read_excel(sheet_path, sheet_name=\"samples\")"
      ],
      "metadata": {
        "id": "mz6s-1fdvWLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VY0eHiYcoY3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq = faq_df['faq'].tolist()\n",
        "samples = samples_df['sample'].tolist()\n",
        "labels = torch.tensor(samples_df['gt_idx'].tolist())\n",
        "categories = faq_df['category'].tolist()"
      ],
      "metadata": {
        "id": "YPKdbMOuwe2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# experiment candidate models\n",
        "\n"
      ],
      "metadata": {
        "id": "u7yzxpRJRy2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(model_id, trust_remote_code=True)\n",
        "faq_emb = model.encode(faq)\n",
        "samples_emb = model.encode(samples)\n",
        "similarities = model.similarity(samples_emb, faq_emb)\n",
        "predicts = torch.max(similarities, axis=1)[1] + 1\n",
        "acc = ((predicts == labels).sum() / labels.shape[0]).item()\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jm8q3gS01z5",
        "outputId": "fe59ac50-81d9-4dbc-f96b-c390acccac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7526881694793701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 2,3,5,10]:\n",
        "  print(f\"Top-{i} Accuracy: {topk_accuracy(similarities, labels, i)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huLmtVFCldKt",
        "outputId": "d71db979-a0e1-48e6-b403-54c41a6459f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Accuracy: 0.7526881694793701\n",
            "Top-2 Accuracy: 0.8817204236984253\n",
            "Top-3 Accuracy: 0.9139785170555115\n",
            "Top-5 Accuracy: 0.9354838728904724\n",
            "Top-10 Accuracy: 0.9569892287254333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_values, top_indices = torch.topk(similarities, k=2, dim=1)\n",
        "\n",
        "margins = top_values[:,0] - top_values[:,1]\n",
        "\n",
        "correct_mask = (predicts == labels)\n",
        "wrong_mask = (predicts != labels)\n",
        "\n",
        "avg_margin_correct = margins[correct_mask].mean().item()\n",
        "avg_margin_wrong = margins[wrong_mask].mean().item()\n",
        "\n",
        "print(f\"Avg margin (correct predictions): {avg_margin_correct:.4f}\")\n",
        "print(f\"Avg margin (wrong predictions): {avg_margin_wrong:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJdyLcZIjN8d",
        "outputId": "7fcbadac-9565-4ca4-e8dd-6501769045b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg margin (correct predictions): 0.1038\n",
            "Avg margin (wrong predictions): 0.0324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_categories = 0\n",
        "for i in range(len(labels)):\n",
        "  if categories[labels[i] - 1] == categories[predicts[i] - 1]:\n",
        "    true_categories += 1\n",
        "print(f\"Accuracy of Predicting in Correct Category: {true_categories / len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFYPGybyn1oR",
        "outputId": "edfa086c-da4f-4c58-ab36-1b88695a1bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Predicting in Correct Category: 0.8279569892473119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (pred, label) in enumerate(zip(predicts, labels)):\n",
        "    if pred != label:\n",
        "        print(f\"Sample {i}: True={label.item()}, Pred={pred.item()}\")\n",
        "        print(\"Query:\", samples[i])\n",
        "        print(\"Top predicted FAQ:\", faq[pred.item() - 1])\n",
        "        print(\"True FAQ:\", faq[label.item()-1])\n",
        "        print(\"---\")\n"
      ],
      "metadata": {
        "id": "jCWu17-0meEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}